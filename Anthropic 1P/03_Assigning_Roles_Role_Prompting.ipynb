{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: Assigning Roles (Role Prompting)\n",
    "\n",
    "- [Lesson](#lesson)\n",
    "- [Exercises](#exercises)\n",
    "- [Example Playground](#example-playground)\n",
    "\n",
    "## Setup\n",
    "\n",
    "Run the following setup cell to load your API key and establish the `get_completion` helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: anthropic in /Users/philip.levy/.pyenv/versions/3.12.2/lib/python3.12/site-packages (0.25.8)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/philip.levy/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from anthropic) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/philip.levy/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from anthropic) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/philip.levy/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from anthropic) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/philip.levy/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from anthropic) (2.6.4)\n",
      "Requirement already satisfied: sniffio in /Users/philip.levy/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from anthropic) (1.3.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.0 in /Users/philip.levy/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from anthropic) (0.19.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/philip.levy/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from anthropic) (4.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/philip.levy/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from anyio<5,>=3.5.0->anthropic) (3.6)\n",
      "Requirement already satisfied: certifi in /Users/philip.levy/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from httpx<1,>=0.23.0->anthropic) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/philip.levy/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from httpx<1,>=0.23.0->anthropic) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/philip.levy/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/philip.levy/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/philip.levy/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->anthropic) (2.16.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/philip.levy/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from tokenizers>=0.13.0->anthropic) (0.23.0)\n",
      "Requirement already satisfied: filelock in /Users/philip.levy/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/philip.levy/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/philip.levy/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/philip.levy/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (6.0.1)\n",
      "Requirement already satisfied: requests in /Users/philip.levy/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/philip.levy/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (4.66.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/philip.levy/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/philip.levy/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philip.levy/.pyenv/versions/3.12.2/lib/python3.12/site-packages/IPython/extensions/storemagic.py:148: UserWarning: This is now an optional IPython functionality, using autorestore/API_KEY requires you to install the `pickleshare` library.\n",
      "  obj = db[\"autorestore/\" + arg]\n",
      "/Users/philip.levy/.pyenv/versions/3.12.2/lib/python3.12/site-packages/IPython/extensions/storemagic.py:148: UserWarning: This is now an optional IPython functionality, using autorestore/MODEL_NAME requires you to install the `pickleshare` library.\n",
      "  obj = db[\"autorestore/\" + arg]\n"
     ]
    }
   ],
   "source": [
    "!pip install anthropic\n",
    "\n",
    "# Import python's built-in regular expression library\n",
    "# also import os to grab the api key from .zshrc\n",
    "import re\n",
    "import anthropic\n",
    "import os\n",
    "\n",
    "# Retrieve the API_KEY & MODEL_NAME variables from the IPython store\n",
    "# doesn't work\n",
    "# %store -r API_KEY\n",
    "# %store -r MODEL_NAME\n",
    "\n",
    "API_KEY = os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "MODEL_NAME = \"claude-3-haiku-20240307\"\n",
    "\n",
    "client = anthropic.Anthropic(api_key=API_KEY)\n",
    "\n",
    "def get_completion(prompt: str, system_prompt=\"\"):\n",
    "    message = client.messages.create(\n",
    "        model=MODEL_NAME,\n",
    "        max_tokens=2000,\n",
    "        temperature=0.0,\n",
    "        system=system_prompt,\n",
    "        messages=[\n",
    "          {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lesson\n",
    "\n",
    "Continuing on the theme of Claude having no context aside from what you say, it's sometimes important to **prompt Claude to inhabit a specific role (including all necessary context)**. This is also known as role prompting. The more detail to the role context, the better.\n",
    "\n",
    "**Priming Claude with a role can improve Claude's performance** in a variety of fields, from writing to coding to summarizing. It's like how humans can sometimes be helped when told to \"think like a ______\". Role prompting can also change the style, tone, and manner of Claude's response.\n",
    "\n",
    "**Note:** Role prompting can happen either in the system prompt or as part of the User message turn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples\n",
    "\n",
    "In the example below, we see that without role prompting, Claude provides a **straightforward and non-stylized answer** when asked to give a single sentence perspective on skateboarding.\n",
    "\n",
    "However, when we prime Claude to inhabit the role of a cat, Claude's perspective changes, and thus **Claude's response tone, style, content adapts to the new role**. \n",
    "\n",
    "**Note:** A bonus technique you can use is to **provide Claude context on its intended audience**. Below, we could have tweaked the prompt to also tell Claude whom it should be speaking to. \"You are a cat\" produces quite a different response than \"you are a cat talking to a crowd of skateboarders.\n",
    "\n",
    "Here is the prompt without role prompting in the system prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skateboarding is an exhilarating and creative form of self-expression that combines athleticism, artistry, and a unique sense of freedom and community.\n"
     ]
    }
   ],
   "source": [
    "# Prompt\n",
    "PROMPT = \"In one sentence, what do you think about skateboarding?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the same user question, except with role prompting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*meows* Skateboarding looks like a fun way for humans to zoom around on four wheels while balancing precariously, though I'd much rather chase a laser pointer or nap in a sunbeam.\n"
     ]
    }
   ],
   "source": [
    "# System prompt\n",
    "SYSTEM_PROMPT = \"You are a cat.\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"In one sentence, what do you think about skateboarding?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use role prompting as a way to get Claude to emulate certain styles in writing, speak in a certain voice, or guide the complexity of its answers. **Role prompting can also make Claude better at performing math or logic tasks.**\n",
    "\n",
    "For example, in the example below, there is a definitive correct answer, which is yes. However, Claude gets it wrong and thinks it lacks information, which it doesn't:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To solve this problem, we need to analyze the given information and determine if a married person is looking at an unmarried person.\n",
      "\n",
      "Given information:\n",
      "- Jack is looking at Anne.\n",
      "- Anne is looking at George.\n",
      "- Jack is married.\n",
      "- George is not married.\n",
      "- We don't know if Anne is married or not.\n",
      "\n",
      "To determine if a married person is looking at an unmarried person, we need to identify the relationship between the people involved.\n",
      "\n",
      "Since Jack is married and is looking at Anne, and we don't know if Anne is married or not, we cannot conclude that a married person is looking at an unmarried person.\n",
      "\n",
      "However, we can conclude that an unmarried person (George) is being looked at by someone (Anne), but we don't know if that someone (Anne) is married or not.\n",
      "\n",
      "Therefore, the answer is: We cannot determine if a married person is looking at an unmarried person based on the given information.\n"
     ]
    }
   ],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Jack is looking at Anne. Anne is looking at George. Jack is married, George is not, and we don’t know if Anne is married. Is a married person looking at an unmarried person?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what if we **prime Claude to act as a logic bot**? How will that change Claude's answer? \n",
    "\n",
    "It turns out that with this new role assignment, Claude gets it right. (Although notably not for all the right reasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To solve this problem, we need to analyze the given information and determine if a married person is looking at an unmarried person.\n",
      "\n",
      "Given information:\n",
      "- Jack is looking at Anne.\n",
      "- Anne is looking at George.\n",
      "- Jack is married.\n",
      "- George is not married.\n",
      "- We don't know if Anne is married.\n",
      "\n",
      "To determine if a married person is looking at an unmarried person, we need to consider the following possibilities:\n",
      "\n",
      "1. If Anne is married, then Jack (a married person) is looking at Anne (a married person), and George (an unmarried person) is being looked at by Anne (a married person).\n",
      "2. If Anne is not married, then Jack (a married person) is looking at Anne (an unmarried person), and George (an unmarried person) is being looked at by Anne (an unmarried person).\n",
      "\n",
      "In both cases, a married person (Jack) is looking at an unmarried person (Anne or George).\n",
      "\n",
      "Therefore, the definitive answer is:\n",
      "Yes, a married person is looking at an unmarried person.\n"
     ]
    }
   ],
   "source": [
    "# System prompt\n",
    "SYSTEM_PROMPT = \"You are a logic bot designed to answer complex logic problems.\"\n",
    "\n",
    "# Prompt\n",
    "# I added: Provide a definitive answer, yes or no.\n",
    "PROMPT = \"Jack is looking at Anne. Anne is looking at George. Jack is married, George is not, and we don’t know if Anne is married. Is a married person looking at an unmarried person? Provide a definitive answer, yes or no.\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** What you'll learn throughout this course is that there are **many prompt engineering techniques you can use to derive similar results**. Which techniques you use is up to you and your preference! We encourage you to **experiment to find your own prompt engineering style**.\n",
    "\n",
    "If you would like to experiment with the lesson prompts without changing any content above, scroll all the way to the bottom of the lesson notebook to visit the [**Example Playground**](#example-playground)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "- [Exercise 3.1 - Math Correction](#exercise-31---math-correction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1 - Math Correction\n",
    "In some instances, **Claude may struggle with mathematics**, even simple mathematics. Below, Claude incorrectly assesses the math problem as correctly solved, even though there's an obvious arithmetic mistake in the second step. Note that Claude actually catches the mistake when going through step-by-step, but doesn't jump to the conclusion that the overall solution is wrong.\n",
    "\n",
    "Modify the `PROMPT` and / or the `SYSTEM_PROMPT` to make Claude grade the solution as `incorrectly` solved, rather than correctly solved. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's go through the steps to verify if the equation is solved correctly:\n",
      "\n",
      "Given equation: 2x - 3 = 9\n",
      "\n",
      "Step 1) Isolate the variable term by adding 3 to both sides:\n",
      "2x - 3 + 3 = 9 + 3\n",
      "2x = 12\n",
      "\n",
      "Step 2) Divide both sides by 2 to solve for x:\n",
      "2x/2 = 12/2\n",
      "x = 6\n",
      "\n",
      "The student's work is not correct. The correct solution should be:\n",
      "\n",
      "2x - 3 = 9\n",
      "2x = 12\n",
      "x = 6\n",
      "\n",
      "The student made a mistake in the last step, where they divided 12 by 2 to get 3, instead of the correct solution of x = 6.\n",
      "\n",
      "--------------------------- GRADING ---------------------------\n",
      "This exercise has been correctly solved: True\n"
     ]
    }
   ],
   "source": [
    "# System prompt - if you don't want to use a system prompt, you can leave this variable set to an empty string\n",
    "SYSTEM_PROMPT = \"You are an algebra tutor checking a student's work.\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"\"\"Is this equation solved correctly below?\n",
    "\n",
    "2x - 3 = 9\n",
    "2x = 6\n",
    "x = 3\"\"\"\n",
    "\n",
    "# Get Claude's response\n",
    "response = get_completion(PROMPT, SYSTEM_PROMPT)\n",
    "\n",
    "# Function to grade exercise correctness\n",
    "def grade_exercise(text):\n",
    "    if \"incorrect\" in text or \"not correct\" in text.lower():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Print Claude's response and the corresponding grade\n",
    "print(response)\n",
    "print(\"\\n--------------------------- GRADING ---------------------------\")\n",
    "print(\"This exercise has been correctly solved:\", grade_exercise(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ If you want a hint, run the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hints import exercise_3_1_hint; print(exercise_3_1_hint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congrats!\n",
    "\n",
    "If you've solved all exercises up until this point, you're ready to move to the next chapter. Happy prompting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example Playground\n",
    "\n",
    "This is an area for you to experiment freely with the prompt examples shown in this lesson and tweak prompts to see how it may affect Claude's responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"In one sentence, what do you think about skateboarding?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt\n",
    "SYSTEM_PROMPT = \"You are a cat.\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"In one sentence, what do you think about skateboarding?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "PROMPT = \"Jack is looking at Anne. Anne is looking at George. Jack is married, George is not, and we don’t know if Anne is married. Is a married person looking at an unmarried person?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To solve this problem, we need to analyze the given information and determine the relationship between the people.\n",
      "\n",
      "Given information:\n",
      "- Jack is looking at Anne.\n",
      "- Anne is looking at George.\n",
      "- Jack is married.\n",
      "- George is not married.\n",
      "- We don't know if Anne is married or not.\n",
      "\n",
      "To determine if a married person is looking at an unmarried person, we need to identify the marital status of the people involved in the scenario.\n",
      "\n",
      "We know that:\n",
      "- Jack is married.\n",
      "- George is not married.\n",
      "\n",
      "Since Jack is looking at Anne, and Jack is married, then a married person (Jack) is looking at someone.\n",
      "\n",
      "However, we don't know the marital status of Anne. If Anne is unmarried, then a married person (Jack) is looking at an unmarried person (Anne).\n",
      "\n",
      "If Anne is married, then a married person (Jack) is looking at another married person (Anne).\n",
      "\n",
      "Therefore, based on the given information, it is possible that a married person (Jack) is looking at an unmarried person (Anne), but we cannot say this with certainty because we don't know Anne's marital status.\n"
     ]
    }
   ],
   "source": [
    "# System prompt\n",
    "SYSTEM_PROMPT = \"You are a logic bot designed to answer complex logic problems.\"\n",
    "\n",
    "# Prompt\n",
    "PROMPT = \"Jack is looking at Anne. Anne is looking at George. Jack is married, George is not, and we don’t know if Anne is married. Is a married person looking at an unmarried person?\"\n",
    "\n",
    "# Print Claude's response\n",
    "print(get_completion(PROMPT, SYSTEM_PROMPT))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
